{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Machine Learning with Python: Project Presentation***\n",
    "---\n",
    "## In partial fulfillment of Simplilearn Master Data Science Certification course | Due Date: Oct 01, 2020  \n",
    "\n",
    "## Project name: Mercedes-Benz Greener Manufacturing.  \n",
    "---\n",
    "### Modeler and presenter : ***Samuel Y. Ntsua***  \n",
    "### Trainer/Mentor : ***Vaishali Balaji***  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examining the data**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can get the dataset directly from github <br>\n",
    "## We just need the path to the raw data location. To do that, we add \"\"?raw=true\" to the url link.\n",
    "import pandas as pd\n",
    "\n",
    "train_path =\"https://github.com/Simplilearn-Edu/Machine-Learning--Projects/blob/master/Projects/Projects%20for%20Submission/Project%201%20-%20Mercedes-Benz%20Greener%20Manufacturing/Dataset%20for%20the%20project/train.zip?raw=true\"\n",
    "test_path =\"https://github.com/Simplilearn-Edu/Machine-Learning--Projects/blob/master/Projects/Projects%20for%20Submission/Project%201%20-%20Mercedes-Benz%20Greener%20Manufacturing/Dataset%20for%20the%20project/test.zip?raw=true\"\n",
    "\n",
    "## load the dataset\n",
    "\n",
    "mbtrain_df = pd.read_csv(train_path, compression='zip', header=0, sep=',', quotechar='\"')\n",
    "mbtest_df = pd.read_csv(test_path, compression='zip', header=0, sep=',', quotechar='\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0 X1  X2 X3 X4 X5 X6 X8  ...  X375  X376  X377  X378  X379  \\\n",
       "0   0  130.81   k  v  at  a  d  u  j  o  ...     0     0     1     0     0   \n",
       "1   6   88.53   k  t  av  e  d  y  l  o  ...     1     0     0     0     0   \n",
       "2   7   76.26  az  w   n  c  d  x  j  x  ...     0     0     0     0     0   \n",
       "3   9   80.62  az  t   n  f  d  x  l  e  ...     0     0     0     0     0   \n",
       "4  13   78.02  az  v   n  f  d  h  d  n  ...     0     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     1     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbtrain_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0 X1  X2 X3 X4 X5 X6 X8  ...  X375  X376  X377  X378  X379  \\\n",
       "0   0  130.81   k  v  at  a  d  u  j  o  ...     0     0     1     0     0   \n",
       "1   6   88.53   k  t  av  e  d  y  l  o  ...     1     0     0     0     0   \n",
       "2   7   76.26  az  w   n  c  d  x  j  x  ...     0     0     0     0     0   \n",
       "3   9   80.62  az  t   n  f  d  x  l  e  ...     0     0     0     0     0   \n",
       "4  13   78.02  az  v   n  f  d  h  d  n  ...     0     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     1     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbtrain_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4209 train observations \n",
      " 378 train columns \n",
      " 4209 test observations \n",
      " 377 test columns\n"
     ]
    }
   ],
   "source": [
    "print(f' {mbtrain_df.shape[0]} train observations \\n {mbtrain_df.shape[1]} train columns \\n {mbtest_df.shape[0]} test observations \\n {mbtest_df.shape[1]} test columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has a 378 columns.  \n",
    "Using the traditional isnull().sum() to check on the missingness will not fit all 387 columns on the screen,  \n",
    "Instead, we can use isnull.any() method to show only those columns that have null.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbtrain_df.columns[mbtrain_df.isnull().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also count the null with:\n",
    "mbtrain_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output shows there is not null values in train.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: If for any column(s), the variance is equal to zero, then you need to remove those variable(s).  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "This task is equivalent to removing columns or predictors with zero or near-zero variance.  \n",
    "One way to identify zero variance features is that they have one unique value.  \n",
    "But one must be careful not to systematically drop near-zero variance predictors as legitimate dummy predictors can have low variance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID      5.941936e+06\n",
       "y       1.607667e+02\n",
       "X10     1.313092e-02\n",
       "X11     0.000000e+00\n",
       "X12     6.945713e-02\n",
       "            ...     \n",
       "X380    8.014579e-03\n",
       "X382    7.546747e-03\n",
       "X383    1.660732e-03\n",
       "X384    4.750593e-04\n",
       "X385    1.423823e-03\n",
       "Length: 370, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####  Variance of each column. (standard deviation ==0 will also do : mbtrain_df.std(axis=0))\n",
    "mbtrain_df.var(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mbtrain_df.var(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object produced by `` mbtrain_df.var(axis=0)`` is a pandas series.  We can enumerate the elements, check if it is equal to zero,  \n",
    "and if it is , we retain the corresponding index.  \n",
    "Those are the features with zero variance to be dropped (they have near zero prediction power)  \n",
    "``enumerate(mbtrain_df.var(axis=0))``  enumerates the elements  \n",
    "``for ind,val in enumerate(mbtrain_df.var(axis=0))`` holds the elements in ind,val  \n",
    "``for ind,val in enumerate(mbtrain_df.var(axis=0)) if val ==0`` checks if val is equal to zero  \n",
    "``ind for ind,val in enumerate(mbtrain_df.var(axis=0)) if val ==0``  retains the corresponding index  \n",
    "``[ind for ind,val in enumerate(mbtrain_df.var(axis=0)) if val ==0]`` packages the results into a list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [ind for ind,val in enumerate(mbtrain_df.var(axis=0)) if val ==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have candidates of zero-variance, let's explore further to see these columns  \n",
    "to see if they are not legitimate dummy variables which can help understand the data as well as the model.  \n",
    "As an example, gender variable is generally represented as 0/1 (or M/F). In a dataset of 10,000 rows, in which 50% is M and the other 50% is F,  \n",
    "(a balance desired to minimize bias) the variance of the gender columns will be zero, but such variable can still contribute to the prediction power of the model.  \n",
    "On the other hand, if only a relatively small fraction (say 2%) of gender is M in the data, it is clear that dropping such gender column will not  \n",
    "reduce the model's power to predict.  \n",
    "With this perspective in mind, let's dig further into our candidate variables to see how uniform their values are across all observation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X85</th>\n",
       "      <th>X99</th>\n",
       "      <th>X225</th>\n",
       "      <th>X227</th>\n",
       "      <th>X260</th>\n",
       "      <th>X281</th>\n",
       "      <th>X282</th>\n",
       "      <th>X285</th>\n",
       "      <th>X289</th>\n",
       "      <th>X322</th>\n",
       "      <th>X339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>s</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206</th>\n",
       "      <td>v</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>r</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208</th>\n",
       "      <td>r</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4209 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1  X85  X99  X225  X227  X260  X281  X282  X285  X289  X322  X339\n",
       "0     v    1    0     0     0     0     0     0     1     0     0     0\n",
       "1     t    1    0     0     0     0     0     0     1     0     0     0\n",
       "2     w    1    0     0     0     0     0     0     0     0     0     0\n",
       "3     t    0    0     0     0     0     0     0     0     0     0     0\n",
       "4     v    0    0     0     0     0     0     0     0     0     0     0\n",
       "...  ..  ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...\n",
       "4204  s    1    0     1     0     0     0     0     1     0     0     0\n",
       "4205  o    0    0     0     0     0     1     0     0     0     0     0\n",
       "4206  v    1    0     0     0     0     0     0     1     0     0     0\n",
       "4207  r    0    0     0     0     0     0     0     0     0     0     0\n",
       "4208  r    0    0     0     0     0     0     0     0     0     0     0\n",
       "\n",
       "[4209 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbtrain_df.iloc[:,to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X1      27\n",
       "X85      2\n",
       "X99      2\n",
       "X225     2\n",
       "X227     2\n",
       "X260     2\n",
       "X281     2\n",
       "X282     2\n",
       "X285     2\n",
       "X289     1\n",
       "X322     2\n",
       "X339     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbtrain_df.iloc[:,to_drop].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X1      vtwtvbrlsbrrbrslraacasaarbrslaasbvebssblvvslha...\n",
       "X85                                                  1718\n",
       "X99                                                    36\n",
       "X225                                                  408\n",
       "X227                                                   13\n",
       "X260                                                    1\n",
       "X281                                                   11\n",
       "X282                                                   17\n",
       "X285                                                  866\n",
       "X289                                                    0\n",
       "X322                                                   92\n",
       "X339                                                    1\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbtrain_df.iloc[:,to_drop].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above three output shows that columns X85, X225 and X285 have non-negligible variability that may contribute the the model's power of prediction.  \n",
    "As such, we keep them, while we drop X99, X227, X260, X281, X282, X289, X322 and X339  \n",
    "The only column of constant value is X289  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Check for null and unique values for test and train sets. \n",
    " \n",
    "---\n",
    "\n",
    "\n",
    "We use the same method as above to check for unique and null in test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking for null in test\n",
    "mbtest_df.columns[mbtest_df.isnull().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbtest_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output shows there is not null values in test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for low-variance in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID      5.871311e+06\n",
       "X10     1.865006e-02\n",
       "X11     2.375861e-04\n",
       "X12     6.885074e-02\n",
       "X13     5.734498e-02\n",
       "            ...     \n",
       "X380    8.014579e-03\n",
       "X382    8.715481e-03\n",
       "X383    4.750593e-04\n",
       "X384    7.124196e-04\n",
       "X385    1.660732e-03\n",
       "Length: 369, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbtest_df.var(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [ind for ind,val in enumerate(mbtest_df.var(axis=0)) if val ==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[242, 243, 280, 281, 353]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X249    2\n",
       "X250    2\n",
       "X287    2\n",
       "X288    2\n",
       "X361    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbtest_df.iloc[:,to_drop].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X249      40\n",
       "X250    2340\n",
       "X287      65\n",
       "X288       1\n",
       "X361    4051\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbtest_df.iloc[:,to_drop].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 378)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbtrain_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X361 has 2 unique values, yet more than 92 % (4051/4209) takes on one of the values. It follows that X361 will not add significant prediction power to the model.  \n",
    "X250's values are about 50/5, thus it should be kept.  \n",
    "X249, X287, and X288 should be dropped from test data.  \n",
    "In all, columns that will be drop in test date will also be dropped from train data, (and vise versa)  \n",
    "because if a column did not participate in building the model, the model will poorly predict when tested on a data with such column.  \n",
    "So we will be dropping : X249, X287, X288 X99, X227, X260, X281, X282, X289, X322 and X339 from both test and train.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbtrain_df.drop(['X249', 'X287', 'X288', 'X99', 'X227', 'X260', 'X281', 'X282', 'X289', 'X322', 'X339'], axis=1, inplace=True)\n",
    "mbtest_df.drop(['X249', 'X287', 'X288', 'X99', 'X227', 'X260', 'X281', 'X282', 'X289', 'X322', 'X339'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " After dropping zero-variance proedictors \n",
      " 4209 train observations \n",
      " 367 train columns \n",
      " 4209 test observations \n",
      " 366 test columns\n"
     ]
    }
   ],
   "source": [
    "print(f' After dropping zero-variance proedictors \\n {mbtrain_df.shape[0]} train observations \\n {mbtrain_df.shape[1]} train columns \\n {mbtest_df.shape[0]} test observations \\n {mbtest_df.shape[1]} test columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Apply label encoder.  \n",
    "\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see all columns that have 'object' as dtype to be label encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing set\n",
    "train2encode = mbtrain_df.select_dtypes(include=['object']).columns\n",
    "# For testing set\n",
    "test2encode = mbtest_df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in columns to be encoded: \n",
      "\n",
      "Training set\n",
      "X0    47\n",
      "X1    27\n",
      "X2    44\n",
      "X3     7\n",
      "X4     4\n",
      "X5    29\n",
      "X6    12\n",
      "X8    25\n",
      "dtype: int64\n",
      "\n",
      "Testing set\n",
      "X0    49\n",
      "X1    27\n",
      "X2    45\n",
      "X3     7\n",
      "X4     4\n",
      "X5    32\n",
      "X6    12\n",
      "X8    25\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of unique values in columns to be encoded: \\n\\nTraining set\\n{mbtrain_df[train2encode].nunique()}\\n\\nTesting set\\n{mbtest_df[test2encode].nunique()}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output shows the number of additional columns that will be generated should we hot-encode the string columns.\n",
    "\n",
    "Label encoding has its flip side. While label encoding converts string categorical to numeric value so that machine learning algorithm can process  \n",
    "the numerical values generated for the categories do not have numerical meaning per se. As such, Machine Learning algorithm may put numerical value on them,   \n",
    "and mislead the algorithm to perform arithmetic operations on them.  \n",
    "As an example, if the 4 values in column X4 are ``{Africa, America, Asia, Europe}``, the label encoding may encode them to ``{0,1,2,3}`` respectively  \n",
    "and then evaluate them as ``Africa < America < Asia < Europe``; a relationship that does not make any sense.  \n",
    "For that reason, the ideal situation is to hot-encode. However, given that the dataset is already huge, hot-encoding X0 for instance will generate additional 48 columns.  \n",
    "Given this situation, we label encode the string columns.  \n",
    "After evaluating the model with label encoded string columns, if we determine a poor performance, and especially, if we determine that some of the non-string features   \n",
    "are not significant, we can drop them and then hot-encode the string columns in an attempt to find a better performing model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's label encode using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelenc = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training set\n",
    "for encoded in enumerate(train2encode):\n",
    "    mbtrain_df[encoded[1]]=labelenc.fit_transform(mbtrain_df[encoded[1]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0  X1  X2  X3  X4  X5  X6  X8  ...  X375  X376  X377  X378  \\\n",
       "0   0  130.81  32  23  17   0   3  24   9  14  ...     0     0     1     0   \n",
       "1   6   88.53  32  21  19   4   3  28  11  14  ...     1     0     0     0   \n",
       "2   7   76.26  20  24  34   2   3  27   9  23  ...     0     0     0     0   \n",
       "3   9   80.62  20  21  34   5   3  27  11   4  ...     0     0     0     0   \n",
       "4  13   78.02  20  23  34   5   3  12   3  13  ...     0     0     0     0   \n",
       "\n",
       "   X379  X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0  \n",
       "2     0     0     1     0     0     0  \n",
       "3     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 367 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbtrain_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing set\n",
    "for encoded in enumerate(test2encode):\n",
    "    mbtest_df[encoded[1]]=labelenc.fit_transform(mbtest_df[encoded[1]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  X0  X1  X2  X3  X4  X5  X6  X8  X10  ...  X375  X376  X377  X378  X379  \\\n",
       "0   1  21  23  34   5   3  26   0  22    0  ...     0     0     0     1     0   \n",
       "1   2  42   3   8   0   3   9   6  24    0  ...     0     0     1     0     0   \n",
       "2   3  21  23  17   5   3   0   9   9    0  ...     0     0     0     1     0   \n",
       "3   4  21  13  34   5   3  31  11  13    0  ...     0     0     0     1     0   \n",
       "4   5  45  20  17   2   3  30   8  12    0  ...     1     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     0     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 366 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbtest_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check if there are duplicates rows.  \n",
    "But first, we need to drop the ID column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping ID\n",
    "mbtrain_df.drop('ID',axis=1,inplace=True)\n",
    "mbtest_df.drop('ID',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "## duplicates rows in training set?\n",
    "print(mbtrain_df.duplicated().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "## duplicates rows in testing set?\n",
    "print(mbtest_df.duplicated().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Perform dimensionality reduction.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing PCA, let's look at the range of the value of the features.  \n",
    "I first start with Python RegEx ``^X`` to target all columns name starting with X.  \n",
    "I use the RegEx to form a boolean list of True/False for columns starting with X/not starting with X, respectively ``mbtrain_df.columns.str.contains(\"^X\")``.  \n",
    "I then select those with ``df.loc[]``  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X0</th>\n",
       "      <td>4209.0</td>\n",
       "      <td>29.760751</td>\n",
       "      <td>13.738338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X1</th>\n",
       "      <td>4209.0</td>\n",
       "      <td>11.113566</td>\n",
       "      <td>8.531001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2</th>\n",
       "      <td>4209.0</td>\n",
       "      <td>17.306486</td>\n",
       "      <td>10.899914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X3</th>\n",
       "      <td>4209.0</td>\n",
       "      <td>2.919696</td>\n",
       "      <td>1.739912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X4</th>\n",
       "      <td>4209.0</td>\n",
       "      <td>2.997862</td>\n",
       "      <td>0.073900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X380</th>\n",
       "      <td>4209.0</td>\n",
       "      <td>0.008078</td>\n",
       "      <td>0.089524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X382</th>\n",
       "      <td>4209.0</td>\n",
       "      <td>0.007603</td>\n",
       "      <td>0.086872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X383</th>\n",
       "      <td>4209.0</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.040752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X384</th>\n",
       "      <td>4209.0</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.021796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X385</th>\n",
       "      <td>4209.0</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.037734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       count       mean        std  min   25%   50%   75%   max\n",
       "X0    4209.0  29.760751  13.738338  0.0  19.0  35.0  43.0  46.0\n",
       "X1    4209.0  11.113566   8.531001  0.0   3.0  13.0  20.0  26.0\n",
       "X2    4209.0  17.306486  10.899914  0.0   8.0  16.0  25.0  43.0\n",
       "X3    4209.0   2.919696   1.739912  0.0   2.0   2.0   5.0   6.0\n",
       "X4    4209.0   2.997862   0.073900  0.0   3.0   3.0   3.0   3.0\n",
       "...      ...        ...        ...  ...   ...   ...   ...   ...\n",
       "X380  4209.0   0.008078   0.089524  0.0   0.0   0.0   0.0   1.0\n",
       "X382  4209.0   0.007603   0.086872  0.0   0.0   0.0   0.0   1.0\n",
       "X383  4209.0   0.001663   0.040752  0.0   0.0   0.0   0.0   1.0\n",
       "X384  4209.0   0.000475   0.021796  0.0   0.0   0.0   0.0   1.0\n",
       "X385  4209.0   0.001426   0.037734  0.0   0.0   0.0   0.0   1.0\n",
       "\n",
       "[365 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For training set\n",
    "mbtrain_df.loc[:,mbtrain_df.columns.str.contains(\"^X\")].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X0</th>\n",
       "      <td>4209.0</td>\n",
       "      <td>30.515324</td>\n",
       "      <td>15.221177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X1</th>\n",
       "      <td>4209.0</td>\n",
       "      <td>11.075315</td>\n",
       "      <td>8.544520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2</th>\n",
       "      <td>4209.0</td>\n",
       "      <td>17.780708</td>\n",
       "      <td>10.227319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X3</th>\n",
       "      <td>4209.0</td>\n",
       "      <td>2.933476</td>\n",
       "      <td>1.776977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X4</th>\n",
       "      <td>4209.0</td>\n",
       "      <td>2.997149</td>\n",
       "      <td>0.078553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X380</th>\n",
       "      <td>4209.0</td>\n",
       "      <td>0.008078</td>\n",
       "      <td>0.089524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X382</th>\n",
       "      <td>4209.0</td>\n",
       "      <td>0.008791</td>\n",
       "      <td>0.093357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X383</th>\n",
       "      <td>4209.0</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.021796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X384</th>\n",
       "      <td>4209.0</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.026691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X385</th>\n",
       "      <td>4209.0</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.040752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       count       mean        std  min   25%   50%   75%   max\n",
       "X0    4209.0  30.515324  15.221177  0.0  20.0  36.0  45.0  48.0\n",
       "X1    4209.0  11.075315   8.544520  0.0   3.0  13.0  20.0  26.0\n",
       "X2    4209.0  17.780708  10.227319  0.0  10.0  17.0  23.0  44.0\n",
       "X3    4209.0   2.933476   1.776977  0.0   2.0   2.0   5.0   6.0\n",
       "X4    4209.0   2.997149   0.078553  0.0   3.0   3.0   3.0   3.0\n",
       "...      ...        ...        ...  ...   ...   ...   ...   ...\n",
       "X380  4209.0   0.008078   0.089524  0.0   0.0   0.0   0.0   1.0\n",
       "X382  4209.0   0.008791   0.093357  0.0   0.0   0.0   0.0   1.0\n",
       "X383  4209.0   0.000475   0.021796  0.0   0.0   0.0   0.0   1.0\n",
       "X384  4209.0   0.000713   0.026691  0.0   0.0   0.0   0.0   1.0\n",
       "X385  4209.0   0.001663   0.040752  0.0   0.0   0.0   0.0   1.0\n",
       "\n",
       "[365 rows x 8 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For testing set\n",
    "mbtest_df.loc[:,mbtest_df.columns.str.contains(\"^X\")].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above that the columns X0 to X8 have mean values in the 10's while the rest have mean that are 1,000 to 10,000 smaller.  \n",
    "This mean we need to normalize  and scale the features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 366)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbtrain_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130.81</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.53</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.26</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.62</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.02</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        y  X0  X1  X2  X3  X4  X5  X6  X8  X10  ...  X375  X376  X377  X378  \\\n",
       "0  130.81  32  23  17   0   3  24   9  14    0  ...     0     0     1     0   \n",
       "1   88.53  32  21  19   4   3  28  11  14    0  ...     1     0     0     0   \n",
       "2   76.26  20  24  34   2   3  27   9  23    0  ...     0     0     0     0   \n",
       "3   80.62  20  21  34   5   3  27  11   4    0  ...     0     0     0     0   \n",
       "4   78.02  20  23  34   5   3  12   3  13    0  ...     0     0     0     0   \n",
       "\n",
       "   X379  X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0  \n",
       "2     0     0     1     0     0     0  \n",
       "3     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 366 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbtrain_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 365)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing and scaling training set (without the target)\n",
    "train_scaler=Normalizer().fit(mbtrain_df.drop('y',1))\n",
    "norm_train_df = train_scaler.transform(mbtrain_df.drop('y',1))\n",
    "norm_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 365)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing and scaling testing set\n",
    "test_scaler=Normalizer().fit(mbtest_df)\n",
    "norm_test_df = test_scaler.transform(mbtest_df)\n",
    "norm_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the right number of dimensions.  \n",
    "Instead of choosing an arbitrary number to start with, let's fit the PCA and   \n",
    "analyze the curve of the cumulative variance and determine a reasonable number of features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca =PCA()\n",
    "pca.fit(norm_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'cumulative explained variance')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f =np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.plot(f)\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the have a graph depicting the \"number of components\" vs \"Cumulative Explained variance\",  \n",
    "the next logical question that follows is how do we pick the most informative components that yield the optimum cumulative explained variance?  \n",
    "To answer that question, we zoom into the graph, especially, at upper left angle where the curve start flattening.  \n",
    "It is the rate (think slope of the slope, or second order derivative) at which the flattening happens that is going to inform us  \n",
    "when/where we should stop looking further.  \n",
    "It seems the elbow of the curve can be cornered in the upper left angle delimited by the cartesian coordinates ``(50, 0.9)``.  \n",
    "So let's zoom in by limiting   \n",
    "the x-axis to 50 ``plt.xlim(0,50)``  \n",
    "the y-axis to [0.9 to 1] ``plt.ylim(.9,1)``   \n",
    "and also add a grid to help us read ``plt.grid(True)``.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(f)\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.grid(True)\n",
    "plt.xlim(0,50)\n",
    "plt.ylim(.9,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, the optimum cumulative explained variance will be between ``[0.95 - 0.99]``  \n",
    "We can create a PCA that captures 97% (middle of ``[0.95 - 0.99]`` ) of variance, but this is a rather arbitrary decision.  \n",
    "So let's use the mean of explained variance method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean explained_variance_ratio is 0.0027397260273972603\n"
     ]
    }
   ],
   "source": [
    "print(f'The mean explained_variance_ratio is {np.mean(pca.explained_variance_ratio_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features whose mean are greater than the mean explained_variance_ratio is 11\n"
     ]
    }
   ],
   "source": [
    "print(f'The number of features whose mean are greater than the mean explained_variance_ratio is {np.sum([pca.explained_variance_ratio_ > np.mean(pca.explained_variance_ratio_)])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this number to the midpoint method discussed above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.97, whiten=True)\n",
    "norm_features = pca.fit_transform(norm_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The midpoint method retains 13 candidate features\n"
     ]
    }
   ],
   "source": [
    "print(f'The midpoint method retains {norm_features.shape[1]} candidate features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More is better, as the saying goes. Let's retain the midpoint method with the 13 features for the prediction.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5: Predict your test_df values using XGBoost.\n",
    "\n",
    "---\n",
    "\n",
    "We have training set and testing set. We want to predict using XGBoost on the testing set.  \n",
    "There are two possible approaches:   \n",
    "a) train the model using the entire training set,then test the model using the testing set.  \n",
    "b) split the training set into train and validation data sets, then test using the testing set.  \n",
    "In this project we are going to use the second approach.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting into training and validations  sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(mbtrain_df.iloc[:,1:], mbtrain_df['y'].values, test_size=0.25, random_state=4321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3156, 365), (1053, 365), (3156,), (1053,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate an XGBoost Regressor class with the following parameters:  \n",
    "We use a squared error loss function ``\"reg:squarederror\"`` as our objective.  \n",
    "To avoid the possibility of overfitting, we set the depth of a tree to 7 ``'max_depth': 7``.  \n",
    "How fast we want the learning algorithm to converge to an optimum solution is set to 0.2 ``'learning_rate': 0.2``  \n",
    "Since we have a lot of features to start with (360+), we set the percent of features (subsample ratio) to   \n",
    "be used per tree to 10% ``'colsample_bytree':0.1``  \n",
    "That will be sampling about 36 features in every boosting iteration.  \n",
    "For a moderate L1 regularization on weights, we set alpha = 10 ``'alpha': 10``.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xgb_reg = xgb.XGBRegressor( objective = 'reg:squarederror', colsample_bytree = 0.1,  learning_rate = 0.2, max_depth = 7, alpha = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fit and validate the training model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xgb_reg.fit(X_train,y_train)\n",
    "train_valid = train_xgb_reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 9.804432369870364\n"
     ]
    }
   ],
   "source": [
    "training_rmse = np.sqrt(mean_squared_error(y_val, train_valid))\n",
    "print(f'Training RMSE: {training_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7896672205622408"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xgb_reg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the  model on unseen data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_preds = train_xgb_reg.predict(mbtest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RMSE: 15.670846627487933\n"
     ]
    }
   ],
   "source": [
    "testing_rmse = np.sqrt(mean_squared_error(mbtrain_df['y'], testing_preds))\n",
    "print(f'Testing RMSE: {testing_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**  \n",
    "We can see that we got a larger RMSE for the testing. This suggest the model did not do well on the testing set.  \n",
    "A better way would be to use the Cross Validation method of XGBoost to help identify the features that will yield a better training RMSE.  \n",
    "We then use the model with a better RMSE to predict.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python38564bitbaseconda44b9844ce50a4462bec359f84c234b50"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
